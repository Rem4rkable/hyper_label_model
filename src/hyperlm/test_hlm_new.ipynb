{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper_label_model import HyperLabelModel\n",
    "hlm = HyperLabelModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def one_vs_all_transform(labels, current_class):\n",
    "    return np.where((labels == current_class) & (labels != -1), 1, 0)\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = np.load(file_path, allow_pickle=True).item()\n",
    "    data = dataset['data']\n",
    "    original_labels = dataset['labels']\n",
    "    num_classes = dataset['k']\n",
    "    \n",
    "    all_probs = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        # Create one-vs-all labels\n",
    "        one_vs_all_labels = one_vs_all_transform(original_labels, class_idx)\n",
    "        \n",
    "        # Run inference\n",
    "        probs = hlm.infer(data, return_probs=True)\n",
    "        all_probs.append(probs)\n",
    "    \n",
    "    # Stack probabilities and get final predictions\n",
    "    all_probs = np.stack(all_probs, axis=-1)\n",
    "    final_predictions = np.argmax(all_probs, axis=-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(final_predictions == original_labels)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = np.load(file_path, allow_pickle=True).item()\n",
    "    data = dataset['data']\n",
    "    original_labels = dataset['labels']\n",
    "    \n",
    "    preds = hlm.infer(data) \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(preds == original_labels.squeeze())\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: artificial-characters_train_dataset, Accuracy: 0.7906\n",
      "Dataset: csgo_train_dataset, Accuracy: 0.8708\n",
      "Dataset: eye_movements_train_dataset, Accuracy: 0.7109\n",
      "Dataset: GesturePhaseSegmentationProcessed_train_dataset, Accuracy: 0.6625\n",
      "Dataset: hs3_train_dataset, Accuracy: 0.9917\n",
      "Dataset: mboosting_train_dataset, Accuracy: 0.7817\n",
      "Dataset: microaggregation2_train_dataset, Accuracy: 0.6293\n",
      "Dataset: mniste_train_dataset, Accuracy: 0.8521\n",
      "Dataset: pendigits_train_dataset, Accuracy: 0.9943\n",
      "Dataset: petfinder_train_dataset, Accuracy: 0.7903\n",
      "Dataset: tree3k_train_dataset, Accuracy: 0.9465\n",
      "Dataset: volcanoes-b2_train_dataset, Accuracy: 0.9688\n",
      "\n",
      "Mean Accuracy:  0.8324486492073054\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "data_folder = 'data'\n",
    "accuracies = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        dataset_name = os.path.splitext(filename)[0]\n",
    "        \n",
    "        accuracy = process_dataset(file_path)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Dataset: {dataset_name}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nMean Accuracy: \", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def one_vs_all_transform(data, current_class):\n",
    "    # Create a copy of the data to avoid modifying the original\n",
    "    one_vs_all_data = np.copy(data)\n",
    "    \n",
    "    # Transform the data: 1 if element equals current_class, 0 otherwise\n",
    "    one_vs_all_data = np.where(one_vs_all_data == current_class, 1, 0)\n",
    "    \n",
    "    # Don't modify -1 values\n",
    "    one_vs_all_data[data == -1] = -1\n",
    "    \n",
    "    return one_vs_all_data\n",
    "\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = np.load(file_path, allow_pickle=True).item()\n",
    "    data = dataset['data']\n",
    "    original_labels = dataset['labels'].astype(np.int64)\n",
    "    num_classes = dataset['k']\n",
    "    \n",
    "    all_probs = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        # Create one-vs-all data\n",
    "        one_vs_all_data = one_vs_all_transform(data, class_idx)\n",
    "        \n",
    "        # Run inference\n",
    "        probs = hlm.infer(one_vs_all_data, return_probs=True)\n",
    "        all_probs.append(probs)\n",
    "    \n",
    "    # Stack probabilities and get final predictions\n",
    "    all_probs = np.stack(all_probs, axis=-1)\n",
    "    final_predictions = np.argmax(all_probs, axis=-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(final_predictions == original_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'tree3k_train_dataset.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: tree3k_train_dataset\n",
      "\n",
      "Dataset: tree3k_train_dataset, Accuracy: 0.4777\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "data_folder = 'data'\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        dataset_name = os.path.splitext(filename)[0]\n",
    "        if 'tree3k' in dataset_name:\n",
    "            print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "            accuracy = process_dataset(file_path)\n",
    "            \n",
    "            print(f\"\\nDataset: {dataset_name}, Accuracy: {accuracy:.4f}\")\n",
    "            print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlm.infer(np.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(-1, 4, size=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('data/tree3k_train_dataset.npy', allow_pickle=True).item()\n",
    "data = dataset['data']\n",
    "original_labels = dataset['labels'].astype(np.int64)\n",
    "num_classes = dataset['k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14400, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465277777777777"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hlm.infer(data) == original_labels.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial-characters_train_dataset size: 8276\n",
      "csgo_train_dataset size: 689\n",
      "eye_movements_train_dataset size: 8857\n",
      "GesturePhaseSegmentationProcessed_train_dataset size: 7996\n",
      "hs3_train_dataset size: 2885\n",
      "mboosting_train_dataset size: 35280\n",
      "microaggregation2_train_dataset size: 16200\n",
      "mniste_train_dataset size: 35280\n",
      "pendigits_train_dataset size: 8902\n",
      "petfinder_train_dataset size: 10794\n",
      "tree3k_train_dataset size: 14400\n",
      "volcanoes-b2_train_dataset size: 8640\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Main execution\n",
    "data_folder = 'data'\n",
    "accuracies = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith('.npy'):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        dataset_name = os.path.splitext(filename)[0]\n",
    "        dataset = np.load(file_path, allow_pickle=True).item()\n",
    "        data = dataset['data']\n",
    "        original_labels = dataset['labels']\n",
    "        print(f'{dataset_name} size: {data.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbm-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
